\documentclass[12pt]{article} 
\title{AI for Alt Text at WinVinaya InfoSystems} 
\author{Hari P\thanks{Representing WinVinaya InfoSystems.}} 
\date{27 January, 2025} 

\begin{document} 
\maketitle 
\clearpage 

\tableofcontents
\clearpage 

\section{Abstract}
This paper presents a comprehensive approach to automating the extraction, analysis, and generation of alternative text (alt-text) for images embedded in Docx documents. By leveraging machine learning models such as Llama 3.2-11B Vision, the study aims to improve document accessibility and streamline data management processes. We propose a methodology where images are first extracted from the document and assessed for the presence of alt-text. The results are meticulously recorded in an Excel file. Subsequently, Llama 3.2-11B Vision generates appropriate alt-text for images lacking descriptions, ensuring accurate context delivery and ease of comprehension for all users. This innovation not only augments document remediation efforts but also exemplifies the integration of artificial intelligence to enhance digital inclusion. 

\section{Introduction}
Document accessibility is a critical component of digital inclusion, particularly for individuals with visual impairments who rely on assistive technologies. Alternative text (alt-text) plays a vital role in ensuring images within documents convey meaningful context. Despite its importance, the manual creation of alt-text is labor-intensive and prone to inconsistencies. This research explores the use of AI-driven methodologies to automate alt-text generation, specifically employing Llama 3.2-11B Vision, a state-of-the-art machine learning model designed for visual understanding and language generation.

\section{Methodology}
\subsection{Overview}
The methodology involves five key phases: image extraction, alt-text identification, status recording, alt-text generation, and document reintegration. Each phase employs advanced libraries and tools, coupled with Llama 3.2-11B Vision’s capabilities, to deliver a seamless and efficient workflow.

\subsection{Technological Framework}
\begin{itemize}
    \item \textbf{Programming Language:} Python 3.10
    \item \textbf{Libraries:} 
    \begin{itemize}
        \item \texttt{python-docx} for image extraction
        \item \texttt{openpyxl} for Excel file management
        \item \texttt{GroqClient} for integrating the Llama 3.2-11B Vision model via Groq API
    \end{itemize}
    \item \textbf{Hardware:} High-performance GPU-enabled systems for model inference
\end{itemize}

\section{Execution Plan}
\subsection*{Step 1: Extract Images from the Document}
Using the \texttt{python-docx} library, images embedded within the Docx document are extracted and stored locally. Each image is assigned a unique identifier for easy tracking.

\subsection*{Step 2: Assess Presence of Alt-Text}
Each image is evaluated for existing alt-text using metadata inspection. If alt-text is present, it is recorded; otherwise, the image is marked for further processing.

\subsection*{Step 3: Record Status in an Excel File}
The findings from Step 2 are logged in an Excel file using \texttt{openpyxl}. The file contains the following columns:
\begin{itemize}
    \item \textbf{Image ID:} Unique identifier for each image
    \item \textbf{Alt-Text Status:} Indicates whether alt-text is present or absent
    \item \textbf{Existing Alt-Text:} If applicable, the alt-text is recorded
\end{itemize}

\subsection*{Step 4: Generate Alt-Text Using Llama 3.2-11B Vision}
Images lacking alt-text are passed through the Llama 3.2-11B Vision model via Groq API. The model generates accurate and context-aware alt-text descriptions, which are reviewed for quality and relevance.

\subsection*{Step 5: Integrate Alt-Text Back into the Document}
The newly generated alt-text is integrated back into the original document at their respective image positions using the \texttt{python-docx} library.

\section{Results}
\subsection{Alt-Text Coverage}
Initial testing on a sample dataset showed a significant improvement in alt-text coverage, with high accuracy for images requiring AI-generated descriptions.

\subsection{Time Efficiency}
The automated workflow reduced the time required for document remediation compared to manual alt-text generation.

\subsection{Quality Assessment}
Human evaluators rated the AI-generated alt-text highly for accuracy, relevance, and contextual understanding.

\section{Discussion}
The findings validate the hypothesis that integrating machine learning models like Llama 3.2-11B Vision can automate alt-text generation effectively. The proposed methodology demonstrated scalability, adaptability, and significant time savings. Challenges such as handling ambiguous or highly abstract images require further refinement in model training.

\section{Conclusion}
The integration of AI for alt-text generation significantly enhances document accessibility and reduces manual effort in remediation processes. Llama 3.2-11B Vision’s capabilities illustrate the potential of AI in bridging accessibility gaps and promoting digital inclusivity.

\section{Future Work}
Future research will focus on:
\begin{itemize}
    \item Expanding the model’s training dataset to handle niche and industry-specific image contexts
    \item Integrating additional languages for multilingual support
    \item Developing a user-friendly interface for non-technical users
\end{itemize}

\section{References}
\begin{itemize}
    \item Meta. "Llama 3.2-11B Vision Model Overview." \textit{Meta Documentation}, 2025.
    \item Python Software Foundation. \textit{python-docx Library Documentation}.
    \item Python Software Foundation. \textit{openpyxl Library Documentation}.
\end{itemize}

\end{document}
